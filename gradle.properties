# Deployment Profiles
deployment.llm.enabled=true          # GPU Instance (Ollama + RAG)
deployment.api.enabled=true          # CPU Instance (API + Frontend)

# Vast.ai Configuration
vast.llm.gpu=RTX4090
vast.llm.vram=24GB
vast.api.cpu=4cores
vast.api.ram=8GB